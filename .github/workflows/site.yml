name: Build site

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"   # hourly; tweak as you like
  push:
    branches: [ main ]

permissions:
  contents: read
  pages: write
  id-token: write

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  SUMMARIZER_MODEL: gpt-4o-mini
  PDF_SUMMARY_MAX_PAGES: "30"
  PDF_SUMMARY_MAX_CHARS: "72000"
  PDF_SUMMARY_MAX_BULLETS: "16"
  PDF_SUMMARY_DEBUG: "1"

jobs:
  scrape:
    runs-on: ubuntu-24.04
    env:
      SALIDA_CIVICCLERK_URL: https://salidaco.civicclerk.com
      SALIDA_CIVICCLERK_ALT_HOSTS: "https://salidaco.civicclerk.com,https://cityofsalida.civicclerk.com"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          elif [ -f scraper/requirements.txt ]; then
            pip install -r scraper/requirements.txt
          else
            echo "requirements.txt not found" && exit 1
          fi

      - name: Install Playwright browsers
        run: python -m playwright install --with-deps chromium

      - name: Print effective PDF limits
        run: |
          python - <<'PY'
          import os
          print("ENV.PDF_SUMMARY_MAX_BULLETS =", os.getenv("PDF_SUMMARY_MAX_BULLETS"))
          print("ENV.PDF_SUMMARY_MAX_PAGES   =", os.getenv("PDF_SUMMARY_MAX_PAGES"))
          print("ENV.PDF_SUMMARY_MAX_CHARS   =", os.getenv("PDF_SUMMARY_MAX_CHARS"))
          PY

      - name: Clear agenda summary cache
        run: rm -rf data/cache/agenda_summaries || true

      - name: Debug hosts
        run: |
          echo "SALIDA_CIVICCLERK_URL=${SALIDA_CIVICCLERK_URL}"
          echo "SALIDA_CIVICCLERK_ALT_HOSTS=${SALIDA_CIVICCLERK_ALT_HOSTS}"

      - name: Run scraper
        run: |
          python -m scraper.main
          test -d data && ls -la data || (echo "no data dir generated" && exit 1)

      # ðŸ”½ THIS is the missing piece
      - name: Summarize agendas (GPT)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Try with explicit args; if the module has no CLI, fall back to default
          python -m scraper.summarize --input data/meetings.json --out data/cache/agenda_summaries || \
          python -m scraper.summarize
          # show what we built
          echo "---- agenda_summaries ----"
          ls -la data/cache/agenda_summaries || true

      - name: Sanity check: did we produce any bullets?
        run: |
          python - <<'PY'
          import json, os, glob, sys
          bullets = 0
          for p in glob.glob("data/cache/agenda_summaries/*.json"):
            try:
              obj = json.load(open(p))
              if obj.get("bullets"): bullets += 1
            except Exception: pass
          print(f"Found {bullets} items with bullets")
          sys.exit(0 if bullets > 0 else 1)
          PY

      - name: Upload data artifact
        uses: actions/upload-artifact@v4
        with:
          name: scrape-data
          path: |
            data/
          if-no-files-found: warn
