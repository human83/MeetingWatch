name: Build site

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"     # hourly; adjust if you want
  push:
    branches: [ main ]

permissions:
  contents: read
  pages: write
  id-token: write

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  SUMMARIZER_MODEL: gpt-4o-mini
  PDF_SUMMARY_MAX_PAGES: "30"
  PDF_SUMMARY_MAX_CHARS: "72000"
  PDF_SUMMARY_MAX_BULLETS: "16"
  PDF_SUMMARY_DEBUG: "1"

jobs:
  scrape:
    runs-on: ubuntu-24.04
    env:
      SALIDA_CIVICCLERK_URL: https://salidaco.civicclerk.com
      SALIDA_CIVICCLERK_ALT_HOSTS: "https://salidaco.civicclerk.com,https://cityofsalida.civicclerk.com"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          elif [ -f scraper/requirements.txt ]; then
            pip install -r scraper/requirements.txt
          else
            echo "requirements.txt not found" && exit 1
          fi

      - name: Install Playwright browsers
        run: python -m playwright install --with-deps chromium

      - name: Print effective PDF limits
        run: |
          python - <<'PY'
          import os
          print("ENV.PDF_SUMMARY_MAX_BULLETS =", os.getenv("PDF_SUMMARY_MAX_BULLETS"))
          print("ENV.PDF_SUMMARY_MAX_PAGES   =", os.getenv("PDF_SUMMARY_MAX_PAGES"))
          print("ENV.PDF_SUMMARY_MAX_CHARS   =", os.getenv("PDF_SUMMARY_MAX_CHARS"))
          PY

      - name: Clear agenda summary cache
        run: rm -rf data/cache/agenda_summaries || true

      - name: Debug hosts
        run: |
          echo "SALIDA_CIVICCLERK_URL=${SALIDA_CIVICCLERK_URL}"
          echo "SALIDA_CIVICCLERK_ALT_HOSTS=${SALIDA_CIVICCLERK_ALT_HOSTS}"

      - name: Run scraper
        run: |
          python -m scraper.main
          test -d data && ls -la data || (echo "no data dir generated" && exit 1)

      # === Summarization step (produces the bullets) ===
      - name: Summarize agendas (GPT)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Try explicit CLI first; ignore failure, then try module fallback
          python -m scraper.summarize --input data/meetings.json --out data/cache/agenda_summaries || true
          python -m scraper.summarize || true
          echo "---- agenda_summaries ----"
          ls -la data/cache/agenda_summaries || true

      - name: "Sanity check: did we produce any bullets?"
        run: |
          # Count JSON files that contain a "bullets" field
          n=$(grep -l '"bullets"' data/cache/agenda_summaries/*.json 2>/dev/null | wc -l || true)
          echo "Files with bullets: ${n}"
          if [ "${n}" -gt 0 ]; then
            exit 0
          else
            echo "No bullets produced by summarizer." >&2
            exit 1
          fi

      - name: Upload data artifact
        uses: actions/upload-artifact@v4
        with:
          name: scrape-data
          path: data/
          if-no-files-found: warn
